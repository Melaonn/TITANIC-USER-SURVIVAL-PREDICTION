**This project uses titanic data for predicting user survial**

**frameworks/stacks used** 

-Database(csv data) setup in GCP Buckets
-ETL Pipeline using Airflow and PostGreSQL
-Data ingestion using PSYCOPG2
- JUPYTER notebook testing
- Building feature store using REDIS
- data processing with feature storing
- model training with Feature Extraction
- training pipeline and data and code versioning
- user app building using flask
- data drift detection using ALIBI-DETECT
- ML monitoring using Grafana and Prometheus
